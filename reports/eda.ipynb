{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8403e47c-5eb7-4975-aae7-f43437571404",
      "metadata": {},
      "source": [
        "# DSCI 310: Airbnb Price Analysis\n",
        "\n",
        "Oliver Gullery, Prithvi Sureka, Riddhi Battu, Rashi Selarka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d1b2a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import folium\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import xgboost as xg\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import requests\n",
        "from branca.colormap import linear"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "375ff9f2-c9ba-4978-a6d6-1907d946aedc",
      "metadata": {},
      "source": [
        "## Aim\n",
        "\n",
        "The aim of this data analysis project is to identify which of the\n",
        "factors in the Airbnb Dataset are strong predictors of price. Doing so\n",
        "will allow us obtain information which can determine if Airbnbs are\n",
        "accurately priced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03805274",
      "metadata": {},
      "outputs": [],
      "source": [
        "# loading the data\n",
        "url_listings = \"http://data.insideairbnb.com/united-states/ny/new-york-city/2024-02-06/visualisations/listings.csv\"\n",
        "\n",
        "data = pd.read_csv(url_listings)\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3555404f-3449-49ba-8765-6b3a7989f36b",
      "metadata": {},
      "source": [
        "### Export the dataset to our data/raw folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c57f4818",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv(\"../data/raw/airbnb_data_2024\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022d8fca-c2c1-4906-aa80-69cab8e37b21",
      "metadata": {},
      "source": [
        "### Data Shape & Datatypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98d655e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Data Shape: {data.shape}\\n')\n",
        "\n",
        "\n",
        "\n",
        "print(f'Data datatypes: \\n{data.dtypes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64900cbd-578e-45ab-9609-e6f56afe8fb0",
      "metadata": {},
      "source": [
        "### Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4c3c71",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.info()\n",
        "\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d1fc4d-b51d-40ca-95e9-d2685e8fcd56",
      "metadata": {},
      "source": [
        "### Identifying Null values & Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc565adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Null Values: {data.isna().sum()}\\n')\n",
        "\n",
        "print(f'Duplicated Values: {data.duplicated().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71a18819-5ea4-4e8a-a217-59547eceb62e",
      "metadata": {},
      "source": [
        "### Correlation Matrix (Ranked with Top Ten Correlations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794d3337",
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating correlation matrix\n",
        "corr_matrix = data.select_dtypes('int64')\n",
        "\n",
        "def rank_correlations(corr_matrix):\n",
        "    # flattening matrix\n",
        "    flattened_matrix = corr_matrix.stack().reset_index()\n",
        "\n",
        "    #renaming columns\n",
        "    flattened_matrix.columns = ['Variable_1', 'Variable_2', 'Correlation']\n",
        "\n",
        "    # removing duplicate variable names\n",
        "    flattened_matrix = flattened_matrix.loc[flattened_matrix['Variable_1'] != flattened_matrix['Variable_2']]\n",
        "\n",
        "    corr_column = flattened_matrix['Correlation']\n",
        "\n",
        "    flattened_matrix = flattened_matrix.iloc[abs(corr_column).argsort()[::-1]]\n",
        "\n",
        "    flattened_matrix = flattened_matrix.loc[flattened_matrix['Correlation'].duplicated()]\n",
        "\n",
        "\n",
        "    print(f'Top 10 Variable Correlations: \\n{flattened_matrix.head(10)}')\n",
        "\n",
        "rank_correlations(corr_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479b4e7c-2fc2-4e0b-96ed-3cf17c9ec483",
      "metadata": {},
      "source": [
        "## Takwaways From Preliminary EDA\n",
        "\n",
        "-   Our shape function tells us we have 48895 rows and 16 features which\n",
        "    includes our target variable `price`.\n",
        "\n",
        "-Looking at the columns from our info() function we can identify that\n",
        "name is text data which could provide some valuable insights. We can\n",
        "also infer that any id information (`id` and `host_id`) and variables\n",
        "such as `host_name` will not provide any key information, thus, we can\n",
        "drop them for our data analysis.\n",
        "\n",
        "-   The describe() function provided key summary statistics for our\n",
        "    numerical columns which included the following metrics: count, mean,\n",
        "    standard deviation, minimum, and maximum. This helps us obtain an\n",
        "    idea as to the spread of our data. Our info() function gave us\n",
        "    further information about the datatypes, columns, and amount of data\n",
        "    we have. Through this analysis in addition to our dtypes() function\n",
        "    we can identify that last_review is an object dtype but could be\n",
        "    converted into a pandas datatime format to further utilize pandas\n",
        "    datatime capabilities. Examples of such would be splitting the data\n",
        "    into year, month and day to identify if there are any temporal\n",
        "    patterns across months or years.\n",
        "\n",
        "-   Our isna() function informed us of the null values which are\n",
        "    included in the dataset. The columns `name` and `host_name` have 16\n",
        "    and 21 null values respectively, we can address this null values by\n",
        "    imputing a blank string to indicate the information is not provided.\n",
        "    Our `reviews_per_month` column and `last_review` column have 10052.\n",
        "    As these have identical amounts of null values, we can assume that\n",
        "    if an Airbnb listing doesn’t have a review, instead of zero the dataset\n",
        "    has a null values. This can be addressed through imputing zero into\n",
        "    the null vaues in the reviews_per_month column. We also saw for `license` that in the situations where they are unlicensed, the dataset has NaN values, so we will also be replacing the NaNs with 'Unlicensed'.\n",
        "\n",
        "### Summary\n",
        "\n",
        "In order to prepare our data for further analysis we must perform some\n",
        "preliminary feature engineering which will involve:\n",
        "* Convert `id` and `host_id` into object datatypes to prepare them to be dropped.\n",
        "* Converting the data type of the `last_review` column, then split the `last_review` into year, month and day.\n",
        "* Imputing zeros into the `reviews_per_month` and 'Unlicensed' into `license` null values\n",
        "* Imputing an empty string into the null values for `name` and `host_name`\n",
        "\n",
        "After these changes are made we can proceed to split our data into a\n",
        "train and test set and label our data by data type (numeric,\n",
        "categorical, text, and drop columns).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87282a7",
      "metadata": {},
      "source": [
        "## Preliminary Feature Engineering\n",
        "In order to prepare our data for further analysis, we must perform some preliminary feature engineering which will involve:\n",
        "\n",
        "1.  **Convert `id` and `host_id` into object datatypes to prepare them\n",
        "    to be dropped.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14a10f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['id'] = str(data['id'])\n",
        "data['host_id'] = str(data['host_id'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff28288e-5758-4465-8fe7-5bc5491aa90d",
      "metadata": {},
      "source": [
        "2.  **Convert the data type of the `last_review` column to datetime.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf33f94",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['last_review'] = pd.to_datetime(data['last_review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69afbbe6-86d2-487b-b907-ae7955b46f14",
      "metadata": {},
      "source": [
        "3.  **Split the `last_review` column into year, month, and day\n",
        "    columns.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a1a90b",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['year'] = data['last_review'].dt.year\n",
        "data['month'] = data['last_review'].dt.month\n",
        "data['day'] = data['last_review'].dt.day"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e89c435-74ce-4c38-88f5-383f7b75deac",
      "metadata": {},
      "source": [
        "4.  **Impute zeros into the `reviews_per_month` and \"Unlicensed\" into `license` column for null\n",
        "    values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa27e32e",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['reviews_per_month'] = data['reviews_per_month'].fillna(0)\n",
        "data['license'] = data['license'].fillna('Unlicensed')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d158d3e1-c7dc-40ac-8f34-0f8c695b492d",
      "metadata": {},
      "source": [
        "5.  **Impute an empty string into the `name` and `host_name` columns for\n",
        "    null values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d83ac4b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "data['name'] = data['name'].fillna('')\n",
        "data['host_name'] = data['host_name'].fillna('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d805f4-08c2-4ab7-a5ee-c250d3404b2b",
      "metadata": {},
      "source": [
        "After these changes are made we can proceed to split our data and\n",
        "perform further analysis.\n",
        "\n",
        "### Putting It All Together\n",
        "\n",
        "Now, let’s put all these steps together to perform the preliminary\n",
        "feature engineering tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65260dd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert last_review to datetime\n",
        "data['last_review'] = pd.to_datetime(data['last_review'])\n",
        "\n",
        "# Extract year, month, and day from last_review\n",
        "data['year'] = data['last_review'].dt.year\n",
        "data['month'] = data['last_review'].dt.month\n",
        "data['day'] = data['last_review'].dt.day\n",
        "\n",
        "# Impute zeros for reviews_per_month null values\n",
        "data['reviews_per_month'] = data['reviews_per_month'].fillna(0)\n",
        "\n",
        "# Impute empty string for name and host_name null values\n",
        "data['name'] = data['name'].fillna('')\n",
        "data['host_name'] = data['host_name'].fillna('')\n",
        "\n",
        "data = data.drop(drop_data, axis=1)\n",
        "\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29d5e2eb-6309-4ab0-a003-2291d6b2a44f",
      "metadata": {},
      "source": [
        "### Splitting Data (Training / Testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db3fc16",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# numeric data\n",
        "numerical_data = data.select_dtypes(include=[\"int64\", \"float64\"])\n",
        "numerical_data = numerical_data.columns\n",
        "\n",
        "# text data\n",
        "text_data = [\"name\"]\n",
        "\n",
        "# drop data\n",
        "drop_data = [\"host_name\", \"host_id\", \"id\"]\n",
        "\n",
        "# Categorical Data\n",
        "categorical_data = data.select_dtypes(include=[\"object\"])\n",
        "categorical_data = categorical_data.columns\n",
        "columns_to_exclude = text_data + drop_data\n",
        "categorical_data = [col for col in categorical_data if col not in columns_to_exclude]\n",
        "\n",
        "\n",
        "print(f'Train Shape: {train_df.shape}\\nTest Shape: {test_df.shape}\\n')\n",
        "print(f\"Numerical Columns: {numerical_data}/n\")\n",
        "print(f\"Categorical Columns: {categorical_data}\\n\")\n",
        "print(f\"Text Data: {text_data}\\n\")\n",
        "print(f\"Drop Columns: {drop_data}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c29269f6-b3a9-47a7-b4f2-145fc00b993d",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (Visualizations)\n",
        "\n",
        "### Figure 1. Map with Distribution of Listings by Location and Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da3055c",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_corr = train_df[numerical_data].corr(method = 'pearson')\n",
        "mask = np.zeros_like(train_corr, dtype=bool)\n",
        "mask[np.triu_indices_from(mask)] = True ## Uncomment to clear half the map\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "sns.heatmap(train_corr, mask=mask, vmin=-1, vmax=1, center=0, linewidths=.5, cmap=\"vlag\")\n",
        "fig.suptitle('Correlation Heat Map of Predictors', fontsize=12)\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ce57bb2",
      "metadata": {},
      "source": [
        "Looking at this map, there appears to be strong multicollinearity between reviews per month and number of reviews, reviews per month and number_of_reviews_ltm (last month?), and between number of reviews and number_of_reviews_ltm (last month?). Thus, we'll probably need to consider interactions between these predictors if we use them in our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b61bc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Setting color limits to more typical range, e.g., 0 to 400\n",
        "# Adjust these values based on your specific dataset and its distribution\n",
        "vmin, vmax = 0, 400\n",
        "\n",
        "sc = plt.scatter(train_df['longitude'], train_df['latitude'], c=train_df['price'], cmap='viridis', s=10, alpha=0.6, vmin=vmin, vmax=vmax)\n",
        "plt.colorbar(sc, label='Price')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Distribution of Listings by Location and Price')\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 8))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed4f412c-065c-423b-bcdb-938baa937617",
      "metadata": {},
      "source": [
        "### Figure 2. Price vs Number of Reviews Coloured by Room Type Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2917ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(20, 6))\n",
        "\n",
        "sns.scatterplot(train_df, x = 'number_of_reviews', y='price', hue='room_type', ax=ax[0])\n",
        "ax[0].set_title(\"Price vs Number of Reviews Coloured by Room Type\")\n",
        "ax[0].set(xlabel=\"# of Reviews\", ylabel=\"Price\")\n",
        "\n",
        "sns.scatterplot(train_df, x = 'number_of_reviews', y='price', hue='room_type', ax=ax[1])\n",
        "ax[1].set_title(\"Price (< 5000) vs Number of Reviews For Clarity\")\n",
        "ax[1].set(xlabel=\"# of Reviews\", ylabel=\"Price\")\n",
        "ax[1].set_ylim(-100, 5000)\n",
        "\n",
        "fig.tight_layout\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a7c0369-8533-407b-a539-1a8eee419089",
      "metadata": {},
      "source": [
        "### Figure 3. Price vs Reviews Per Month Coloured by Room Type Scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac486fb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(20, 6))\n",
        "\n",
        "sns.scatterplot(train_df, x = 'reviews_per_month', y='price', hue='room_type', ax=ax[0])\n",
        "ax[0].set_title(\"Price vs Reviews Per Month Coloured by Room Type\")\n",
        "ax[0].set(xlabel=\"# of Reviews Per Month\", ylabel=\"Price\")\n",
        "\n",
        "sns.scatterplot(train_df, x = 'reviews_per_month', y='price', hue='room_type', ax=ax[1])\n",
        "ax[1].set_title(\"Price (< 5000) vs Reviews Per Month For Clarity\")\n",
        "ax[1].set(xlabel=\"# of Reviews Per Month\", ylabel=\"Price\")\n",
        "ax[1].set_ylim(-100, 5000)\n",
        "\n",
        "fig.tight_layout\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad8f4bff-1f38-4966-a1da-6a5514114394",
      "metadata": {},
      "source": [
        "### Figure 4. Neighbourhood Group vs Log Scaled Price Coloured Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a52f45",
      "metadata": {},
      "outputs": [],
      "source": [
        "log_price = np.log(train_df['price'])\n",
        "sns.boxplot(data=train_df, x=log_price, y='neighbourhood_group')\n",
        "plt.title(\"Boxplot of Neighbourhood Group vs Log Price\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f968108f-e60d-4b49-8ece-f7ae1c011d00",
      "metadata": {},
      "source": [
        "### Figure 5. Room Type Vs Price Box plot\n",
        "\n",
        "-   This visualiation was created to see if there is any relationship\n",
        "    between room type and price.\n",
        "-   As we can see price differs among the different room types\n",
        "    indicating that room type may be able to account for the variation\n",
        "    in price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15dc0abf",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(data=train_df, x='price', y='room_type')\n",
        "plt.title(\"Boxplot of Price against Room Type\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c1dcb5-d2ba-4bc2-a131-e2660106f749",
      "metadata": {},
      "source": [
        "# Preprocessing & Transformations\n",
        "\n",
        "# Preparing Data\n",
        "\n",
        "Splitting Data into train and test set and performing imputation on\n",
        "missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e35e85",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = train_df['price']\n",
        "y_test = test_df['price']\n",
        "X_train = train_df.drop('price', axis=1)\n",
        "X_test = test_df.drop('price', axis=1)\n",
        "\n",
        "def impute_random(df, column_name):\n",
        "    probs = df[column_name].value_counts(normalize=True)\n",
        "    missing = df[column_name].isna()\n",
        "    imputed_data = np.random.choice(probs.index, size=missing.sum(), p=probs.values)\n",
        "    df.loc[missing, column_name] = imputed_data  # Corrected variable name here\n",
        "    return df\n",
        "\n",
        "\n",
        "#numerical_data = numerical_data.tolist()  # Convert to list if it's not already\n",
        "\n",
        "# Check if 'last_review' exists in numerical_data before removing\n",
        "if 'last_review' in numerical_data:\n",
        "    numerical_data.remove('last_review')\n",
        "\n",
        "date_data = ['year', 'month', 'day']\n",
        "\n",
        "# Performing imputation on the null values in our date info\n",
        "for i in date_data:  # Corrected the loop variable name\n",
        "    X_train = impute_random(X_train, i)  # Ensure correct function call\n",
        "    X_test = impute_random(X_test, i)  # Corrected the function name and the argument"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df39b71-6cc4-47f4-8e01-beefecc8f0c4",
      "metadata": {},
      "source": [
        "## Defining Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52df4da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numerical Transformer\n",
        "numerical_transformer = StandardScaler()\n",
        "\n",
        "numerical_transformer.fit(X_train)  # fitting the transformer on the train split\n",
        "X_train_scaled = numerical_transformer.transform(X_train)  # transforming the train split\n",
        "X_test_scaled = numerical_transformer.transform(X_test)  # transforming the test split\n",
        "\n",
        "# Categorical Transformer\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "X_train_cat = categorical_transformer.transform(X_train)  # transforming the train split\n",
        "X_test_cat = categorical_transformer.transform(X_test)  # transforming the test split\n",
        "\n",
        "# Text Data Transformer\n",
        "text_transformer = CountVectorizer()\n",
        "X_train_text = text_transformer.transform(X_train)  # transforming the train split\n",
        "X_test_text = text_transformer.transform(X_test)  # transforming the test split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1a5a509-62df-400e-a02a-229b6d294ade",
      "metadata": {},
      "source": [
        "# Creating a Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e475f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_dict = {}\n",
        "\n",
        "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
        "    \"\"\"\n",
        "    Returns mean and std of cross validation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model :\n",
        "        scikit-learn model\n",
        "    X_train : numpy array or pandas DataFrame\n",
        "        X in the training data\n",
        "    y_train :\n",
        "        y in the training data\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "        pandas Series with mean scores from cross_validation\n",
        "    \"\"\"\n",
        "\n",
        "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
        "\n",
        "    mean_scores = pd.DataFrame(scores).mean()\n",
        "    std_scores = pd.DataFrame(scores).std()\n",
        "    out_col = []\n",
        "\n",
        "    for i in range(len(mean_scores)):\n",
        "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
        "\n",
        "    return pd.Series(data=out_col, index=mean_scores.index)\n",
        "\n",
        "dummy = DummyRegressor(strategy=\"median\")\n",
        "results_dict[\"dummy\"] = mean_std_cross_val_scores(\n",
        "    dummy, X_train, y_train, return_train_score=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ce95d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(results_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed27d14",
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessor = make_column_transformer(\n",
        "    ('drop', drop_data),\n",
        "    (numerical_transformer, numerical_data),\n",
        "    (categorical_transformer, categorical_data),\n",
        "    (text_transformer, text_data),\n",
        "    remainder='passthrough'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed78b3de",
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = make_pipeline(preprocessor, reg)\n",
        "pipe.fit(X_train, y_train)\n",
        "# pipe.predict(y_train)\n",
        "# f'Test Score is: {pipe.score(X_train, y_train)}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c08301",
      "metadata": {},
      "outputs": [],
      "source": [
        "ols = LinearRegression()\n",
        "model = ols.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "825c7a2b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dsci",
      "language": "python",
      "name": "conda-env-dsci-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
